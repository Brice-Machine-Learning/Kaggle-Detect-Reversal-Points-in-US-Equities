{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ðŸ§© **02 â€” Feature Engineering**\n",
    "\n",
    "**Notebook Purpose:**\n",
    "Transform insights from exploratory data analysis into *explicit, reproducible features* suitable for time-series classification. This notebook focuses on constructing lagged, rolling, and event-aware features while preserving temporal integrity and avoiding data leakage.\n",
    "\n",
    "---\n",
    "\n",
    "**Competition:** *Detect Reversal Points in US Equities*\n",
    "**Deadline:** December 31, 2025\n",
    "**Repository:** `Kaggle-Detect-Reversal-Points-in-US-Equities`\n",
    "**Author:** Brice Nelson\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Date Created:** 2025-12-15<br>\n",
    "**Notebook Last Updated:** 2025-12-15\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§­ **Goals of This Notebook**\n",
    "\n",
    "- Ingest validated raw and baseline datasets\n",
    "- Engineer time-aware features derived from Signal Descriptor columns\n",
    "- Construct lag-based and rolling window features without leakage\n",
    "- Encode sparse event information relevant to reversal detection\n",
    "- Maintain compatibility with baseline and advanced modeling pipelines\n",
    "- Persist engineered datasets to `/data/processed/`\n",
    "- Document feature rationale for downstream interpretation\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— **Context from Prior Analysis**\n",
    "\n",
    "Feature engineering decisions in this notebook are informed by findings from the light EDA phase, including:\n",
    "\n",
    "- Extremely wide feature space dominated by boolean Signal Descriptor columns\n",
    "- Sparse, event-based target labels (`H`, `L`, `None`)\n",
    "- Strong temporal ordering within each `ticker_id`\n",
    "- Need for models robust to high-dimensional, sparse inputs\n",
    "\n",
    "Detailed exploratory analysis and visualization are deferred to\n",
    "`01_eda_detailed.ipynb`.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‚ **References**\n",
    "\n",
    "- Light EDA: `notebooks/01_eda.ipynb`\n",
    "- Detailed EDA (planned): `notebooks/01_eda_detailed.ipynb`\n",
    "- Project Plan: `docs/00_overview/01_reversal_points_project_plan.md`\n",
    "- Feature Design Notes: `docs/03_notebooks/02_notebook_notes/03_feature_engineering/01_feature_engineering.md`\n",
    "- Project Structure: `docs/01_architecture/01_project_structure.md`\n"
   ],
   "id": "aa1850edb2530697"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T04:25:32.639525385Z",
     "start_time": "2025-12-18T04:25:32.571310081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.data.eda_utils import get_prefix_counts\n",
    "\n",
    "# configurations\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ],
   "id": "a85b32c50a987f92",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Raw Data\n",
    "- Load via Duckdb\n",
    "- Create a connection\n",
    "- Load the training and test datasets into dataframes"
   ],
   "id": "b71f46273d27eafa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-18T04:25:48.354461683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create duckdb connection\n",
    "\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create duckdb dataframe\n",
    "\n",
    "train_df = conn.execute(\"\"\"\n",
    "                        SELECT * FROM\n",
    "                            read_csv_auto('../data/raw/new_competition_data/train.csv',\n",
    "                            max_line_size=5000000)\"\"\").df()\n",
    "test_df = conn.execute(\"\"\"\n",
    "                       SELECT * FROM\n",
    "                           read_csv_auto('../data/raw/new_competition_data/test.csv',\n",
    "                           max_line_size=5000000)\"\"\").df()\n",
    "\n",
    "print('Train dataframe created.')\n",
    "print('Test dataframe created.')"
   ],
   "id": "97c2c37ea93dcae2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Shape\n",
    "\n",
    "print('Train dataframe shape:', train_df.shape)\n",
    "print('Test dataframe shape:', test_df.shape)"
   ],
   "id": "aa9cb3465c6b84e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Register for SQL use\n",
    "duckdb.register('train', train_df)\n",
    "duckdb.register('test', test_df)\n",
    "\n",
    "# Convert column names into pandas DataFrames\n",
    "col_df = pd.DataFrame({'column_name': train_df.columns})\n",
    "duckdb.register('cols', col_df)\n",
    "\n",
    "# Extract prefixes and count them\n",
    "duckdb.query(\"\"\"\n",
    "    SELECT\n",
    "        regexp_extract(column_name, '^[^_]+') AS prefix,\n",
    "        COUNT(*) AS count\n",
    "    FROM cols\n",
    "    GROUP BY prefix\n",
    "    ORDER BY count DESC\n",
    "\"\"\").df()\n"
   ],
   "id": "9d01b396f12e361b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify Signal Columns (Once, Explicitly)\n",
    "\n",
    "signal_cols = [\n",
    "    col for col, dtype in zip(train_df.columns, train_df.dtypes)\n",
    "    if dtype == \"bool\"\n",
    "]\n",
    "\n",
    "len(signal_cols)\n"
   ],
   "id": "aa6d6185098e44c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Signal Population Features (DuckDB SQL)\n",
    "\n",
    "signal_array_expr = \", \".join(f'\"{col}\"' for col in signal_cols)\n",
    "\n",
    "\n",
    "signal_count = len(signal_cols)\n"
   ],
   "id": "c0ffdf303604eb2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a View with Signal Count (DuckDB)\n",
    "\n",
    "conn.execute(f\"\"\"\n",
    "CREATE OR REPLACE VIEW train_signal_counts AS\n",
    "SELECT\n",
    "    *,\n",
    "    (\n",
    "        SELECT SUM(CAST(val AS INT))\n",
    "        FROM UNNEST([{signal_array_expr}]) AS t(val)\n",
    "    ) AS signal_count\n",
    "FROM train_df\n",
    "\"\"\")\n"
   ],
   "id": "d66ec81774f060b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify the datetime column explicitly\n",
    "\n",
    "time_cols = train_df.select_dtypes(include=[\"datetime64\"]).columns\n",
    "time_cols\n",
    "\n"
   ],
   "id": "bfdc39c04e6d147e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert len(time_cols) == 1, f\"Expected 1 datetime column, found {len(time_cols)}\"\n",
    "TIME_COL = time_cols[0]\n",
    "TIME_COL\n"
   ],
   "id": "ffc7c6014763c607",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate boolean signals (this should run fast)\n",
    "train_df[\"signal_count\"] = train_df[signal_cols].sum(axis=1)\n",
    "\n",
    "n_signals = len(signal_cols)\n",
    "train_df[\"signal_density\"] = train_df[\"signal_count\"] / n_signals\n",
    "\n",
    "\n"
   ],
   "id": "ad783d0819e17437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quick sanity checks (train only)\n",
    "\n",
    "train_df[[\"signal_count\", \"signal_density\"]].describe()\n"
   ],
   "id": "2f5cd29307ae0881",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quick sanity checks (train only)\n",
    "\n",
    "train_df[[TIME_COL, \"signal_count\"]].head()\n"
   ],
   "id": "614bd83ab3c80ae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_df = train_df.sort_values(\n",
    "    by=[\"ticker_id\", TIME_COL],\n",
    "    kind=\"mergesort\"   # stable + memory-friendly\n",
    ").reset_index(drop=True)\n"
   ],
   "id": "e2ed155dc2b90a65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e37ce91e492495ea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
