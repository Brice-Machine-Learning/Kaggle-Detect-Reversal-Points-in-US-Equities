{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìä **01 ‚Äî Exploratory Data Analysis (EDA)**\n",
    "\n",
    "**Notebook Purpose:**\n",
    "Perform a *light, structured exploration* of the Kaggle **Detect Reversal Points in U.S. Equities** dataset. This notebook focuses on understanding distributions, spotting anomalies, mapping feature groups, and laying the groundwork for preprocessing and feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "**Competition:** *Detect Reversal Points in US Equities*\n",
    "**Deadline:** December 31, 2025\n",
    "**Repository:** `Kaggle-Detect-Reversal-Points-in-US-Equities`\n",
    "**Author:** Brice Nelson\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Date Created:** 2025-11-29\n",
    "**Notebook Last Updated:** 2025-11-29\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ **Goals of This Notebook**\n",
    "\n",
    "- Load raw Kaggle training and test data (`/data/raw/`)\n",
    "- Inspect dataset shape, dtypes, and missing values\n",
    "- Explore Signal Descriptor columns\n",
    "- Examine target class distribution (0‚Äì3)\n",
    "- Identify time-related patterns and potential leakage risks\n",
    "- Save EDA plots into `/figures/eda/`\n",
    "- Produce initial notes for feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ **References**\n",
    "\n",
    "- Project Plan: `docs/00_overview/01_reversal_points_project_plan.md`\n",
    "- Folder Explanations: `docs/01_architecture/02_folder_explanations.md`\n",
    "- Project Structure: `docs/01_architecture/01_project_structure.md`\n"
   ],
   "id": "4ceab39a252638d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T03:49:25.535364Z",
     "start_time": "2025-11-30T03:49:25.416362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# configurations\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n"
   ],
   "id": "6cf1a970fb8a91db",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Raw Data\n",
    "- Load via Duckdb\n",
    "- Create a connection\n",
    "- Load the training and test datasets into dataframes\n"
   ],
   "id": "5eb84b20693d5c9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:03:35.097599Z",
     "start_time": "2025-11-30T04:00:31.382049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create duckdb connection\n",
    "\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create duckdb dataframe\n",
    "\n",
    "train_df = conn.execute(\"\"\"\n",
    "                        SELECT * FROM\n",
    "                            read_csv_auto('../data/raw/new_competition_data/train.csv',\n",
    "                            max_line_size=5000000)\"\"\").df()\n",
    "test_df = conn.execute(\"\"\"\n",
    "                       SELECT * FROM\n",
    "                           read_csv_auto('../data/raw/new_competition_data/test.csv',\n",
    "                           max_line_size=5000000)\"\"\").df()\n",
    "\n",
    "print('Train dataframe created.')\n",
    "print('Test dataframe created.')"
   ],
   "id": "46a39e833733998f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80868855461f4d1ea25189a8c2a318d8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f0732f0ce7d4ba2ac94ba54869cbe64"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe created.\n",
      "Test dataframe created.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explore Descriptive Statistics",
   "id": "713ab65314afab51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:06:39.026487Z",
     "start_time": "2025-11-30T04:06:39.021827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shape\n",
    "\n",
    "print('Train dataframe shape:', train_df.shape)\n",
    "print('Test dataframe shape:', test_df.shape)\n"
   ],
   "id": "8e2edbefc65a026c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (2683, 68507)\n",
      "Test dataframe shape: (1151, 68506)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:08:47.089612Z",
     "start_time": "2025-11-30T04:08:46.842632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train df info\n",
    "\n",
    "train_df.info()"
   ],
   "id": "d30eff2915221fd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2683 entries, 0 to 2682\n",
      "Columns: 68507 entries, train_id to class_label\n",
      "dtypes: bool(68499), datetime64[us](1), float64(4), int64(1), object(2)\n",
      "memory usage: 175.4+ MB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:09:12.105823Z",
     "start_time": "2025-11-30T04:09:10.487703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test df info\n",
    "\n",
    "test_df.info()"
   ],
   "id": "a031ce49d0ded814",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1151 entries, 0 to 1150\n",
      "Columns: 68506 entries, id to zone_99.5\n",
      "dtypes: bool(68499), datetime64[us](1), float64(4), int64(1), object(1)\n",
      "memory usage: 75.3+ MB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ü¶Ü Why Use DuckDB for This EDA?\n",
    "\n",
    "This dataset is extremely *wide* ‚Äî more than **68,000 columns** of boolean and numeric features.\n",
    "Instead of forcing pandas to scan tens of thousands of columns, DuckDB lets us work directly with the dataset **metadata**, making EDA faster and more efficient.\n",
    "\n",
    "### üîë Key Advantages\n",
    "- **Instant schema inspection** via `pragma_table_info()`\n",
    "- **Fast prefix-based grouping** to discover feature families\n",
    "- **Easy train/test column alignment checks**\n",
    "- **Vectorized SQL operations** that scale better than Python loops\n",
    "\n",
    "In short:\n",
    "**DuckDB handles wide datasets with ease, giving us a cleaner, faster EDA workflow.**\n"
   ],
   "id": "c77f9f885e0d1af4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç DuckDB + Pandas Data Workflow (Short Summary)\n",
    "\n",
    "For this project, we use a hybrid approach that combines the speed of **DuckDB** with the flexibility of **pandas**:\n",
    "\n",
    "1. **Load CSVs with DuckDB** using `read_csv_auto()` for fast ingestion of 68,000+ columns.\n",
    "2. **Convert results to pandas** via `.df()` so the data is ready for modeling (LightGBM, sklearn, etc.).\n",
    "3. **Register the pandas DataFrames back into DuckDB** so we can run fast SQL queries for:\n",
    "   - prefix-based feature grouping\n",
    "   - schema comparisons (train vs. test)\n",
    "   - constant-column detection\n",
    "   - metadata inspection via `pragma_table_info()`\n",
    "\n",
    "This workflow gives us **fast schema exploration** with DuckDB and **full ML compatibility** with pandas ‚Äî the best setup for extremely wide datasets.\n"
   ],
   "id": "7677cd15cd4c27ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T04:52:33.443565Z",
     "start_time": "2025-11-30T04:52:12.782729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Register for SQL use\n",
    "duckdb.register('train', train_df)\n",
    "duckdb.register('test', test_df)\n",
    "\n",
    "# Convert column names into pandas DataFrames\n",
    "col_df = pd.DataFrame({'column_name': train_df.columns})\n",
    "duckdb.register('cols', col_df)\n",
    "\n",
    "# Extract prefixes and count them\n",
    "duckdb.query(\"\"\"\n",
    "    SELECT\n",
    "        regexp_extract(column_name, '^[^_]+') AS prefix,\n",
    "        COUNT(*) AS count\n",
    "    FROM cols\n",
    "    GROUP BY prefix\n",
    "    ORDER BY count DESC\n",
    "\"\"\").df()\n",
    "\n"
   ],
   "id": "f1193fda5c5d83ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      prefix  count\n",
       "0     occurs  34220\n",
       "1    happens  34220\n",
       "2      cross     26\n",
       "3       zone     13\n",
       "4   trending     10\n",
       "5    troughs      5\n",
       "6      peaks      5\n",
       "7         sm      2\n",
       "8          t      1\n",
       "9   momentum      1\n",
       "10     class      1\n",
       "11    ticker      1\n",
       "12     train      1\n",
       "13     ratio      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occurs</td>\n",
       "      <td>34220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happens</td>\n",
       "      <td>34220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cross</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zone</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trending</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>troughs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peaks</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sm</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>momentum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ticker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4e2d6a612f41270"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
