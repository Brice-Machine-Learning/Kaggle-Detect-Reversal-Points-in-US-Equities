# ğŸ“ˆ Detecting Reversal Points in U.S. Equities  

>*Kaggle Competition Â· Time-Series Classification Â· Portfolio Project*

![Status: In Progress](https://img.shields.io/badge/Status-In%20Progress-yellow?style=flat-square)
![Category: Time Series](https://img.shields.io/badge/Category-Time%20Series-blue?style=flat-square)
![Primary Metric: Macro F1](https://img.shields.io/badge/Primary%20Metric-Macro%20F1-orange?style=flat-square)
![Models: LightGBM | CatBoost](https://img.shields.io/badge/Models-LightGBM%20%7C%20CatBoost-brightgreen?style=flat-square)

---

## ğŸ§  Overview  

This repository implements a machine learning system to **detect market reversal points**â€”local highs (H), local lows (L), and non-reversal pointsâ€”using anonymized U.S. equities data from the Kaggle competition **Detecting Reversal Points in US Equities**.

Reversal detection is essential for:

- trend identification  
- swing-based trading strategies  
- volatility modeling  
- market structure analysis  

The project is executed in **two tracks**:

### **Track A â€” Competition Submission (Nov 23â€“Dec 31, 2025)**  

A fast, clean baseline pipeline optimized to meet the competition deadline.

### **Track B â€” Portfolio Expansion (Jan 1â€“Feb 15, 2026)**  

A complete quant-grade system featuring advanced engineered features, SHAP analysis, documentation, and production-oriented ML code structure.

---

## ğŸ¯ Objectives  

- Build a reproducible ML pipeline for detecting reversal points  
- Produce a valid Kaggle submission before the deadline  
- Expand the project into a polished portfolio deliverable  
- Explore engineered time-series features (lags, rolling windows, volatility)  
- Apply and interpret multiple model families  
- Deliver a full final report suitable for recruiters and hiring teams  

---

## ğŸ—‚ï¸ Project Structure (Overview)  

This repository uses a **modular, production-quality layout** containing:

- Segregated raw and processed data  
- Notebooks for EDA, baseline modeling, feature engineering, and advanced training  
- A structured `/src` directory for reusable code  
- A `/docs` directory for deep technical and portfolio-grade documentation  
- Saved models and metadata  
- Kaggle submissions and figures  

The **complete, authoritative project directory tree** is maintained at:

ğŸ‘‰ **`docs/01_architecture/01_project_structure.md`**

This prevents duplication and ensures the README always stays aligned with the canonical structure.

---

## ğŸ§© Technical Approach  

### **1. Exploratory Data Analysis**

- Light EDA for Kaggle submission  
- Full EDA (Jan) with:
  - rolling window visualization  
  - volatility signatures  
  - swing class distribution analysis  
  - Signal Descriptor behavior  

### **2. Preprocessing**

- Time-based splitting (no leakage)  
- Conversion of boolean descriptors  
- Selective scaling  
- Consistent feature alignment between train/test  

### **3. Feature Engineering (Portfolio Track)**

- Lag features (1, 3, 5, 10 periods)  
- Rolling mean, std, min, max  
- Momentum and returns  
- Volatility features  
- Signal Descriptor interactions  

### **4. Modeling**

- Baseline: Logistic Regression, LightGBM  
- Advanced: LightGBM, CatBoost, ensembles  
- Time-series cross-validation  
- Macro-F1 optimization  
- Threshold tuning  
- SHAP values + model interpretability  

---

## ğŸ† Competition Results  

**Status:** Baseline submission planned before Dec 31  

- **Public Leaderboard Score:** *TBD*  
- **Baseline Model:** LightGBM (raw + simple features)  
- **Portfolio Model:** Scheduled for Janâ€“Feb 2026  

---

## ğŸ“… Project Timeline

| Phase | Dates | Summary |
|------|--------|---------|
| Phase 1 â€” Setup | Nov 23â€“24 | Env + repo initialization |
| Phase 2 â€” Light EDA | Nov 25â€“27 | Initial exploration |
| Phase 3 â€” Baseline Preprocessing | Nov 28â€“30 | Clean & prepare data |
| Phase 4 â€” Baseline Modeling | Dec 1â€“10 | Build + evaluate baseline |
| Phase 5 â€” Holiday Buffer | Dec 11â€“26 | Light maintenance |
| Phase 6 â€” Final Submission | Dec 27â€“31 | Submit & document |
| Phase 7 â€” Full EDA | Jan 1â€“10 | Deep time-series exploration |
| Phase 8 â€” Feature Engineering | Jan 10â€“25 | Build advanced features |
| Phase 9 â€” Advanced Modeling | Jan 25â€“Feb 5 | Train + interpret |
| Phase 10 â€” Final Report | Feb 5â€“Feb 15 | Portfolio packaging |

More detail available in:

ğŸ‘‰ `docs/00_overview/reversal_points_project_plan.md`

---

## ğŸ”§ Environment Setup  

### **Conda Environment**

```bash
conda env create -f environment.yml
conda activate reversal_points
```

### Includes

- numpy, pandas, scikit-learn  
- lightgbm, xgboost, catboost  
- optuna + optuna-integration  
- ipywidgets (required for Optuna visualization)  
- matplotlib, seaborn  

### **Kaggle CLI**

```bash
kaggle competitions download -c detecting-reversal-points-in-us-equities
```

---

## ğŸ“¤ Submissions  

All competition submission files are stored under:

```text
/submissions/
    submission_baseline.csv
    submission_final.csv
```

---

## ğŸ“š Final Report (Coming Feb 2026)

The final report will include:

- Feature engineering breakdown  
- SHAP and importance analysis  
- Modeling performance  
- Error analysis  
- Portfolio narrative and insights  

---

## ğŸ¤ Contributions  

The project is open to collaboration and feedback on:

- feature engineering  
- validation methods  
- time-series modeling  
- code architecture  

---

## ğŸ“œ License  

MIT License
See `LICENSE` for details.
